{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "#### Model training using the TPOT exported pipeline and, then, model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tpot.builtins import StackingEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take the engineered data and perform split between train and test set. After some tentative we found that 20% for the test set and 80% for the training set was the best solution.\n",
    "\n",
    "#### After the splitting, we save the training and test features in order to perform some prediction evaluations if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_data = pd.read_json(\"../data/engineered/presences.json\")\n",
    "features = tpot_data.drop('target', axis=1)\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'], test_size=0.20 ,random_state=None)\n",
    "\n",
    "training_features.to_json(\"../data/engineered/presencesTrain.json\")\n",
    "testing_features.to_json(\"../data/engineered/presencesTest.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution of the TPOT exported pipeline with subsequent predictions saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_pipeline = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    RobustScaler(),\n",
    "    StackingEstimator(estimator=SGDRegressor(alpha=0.01, eta0=0.1, fit_intercept=False, l1_ratio=0.5, learning_rate=\"invscaling\", loss=\"squared_loss\", penalty=\"elasticnet\", power_t=0.1)),\n",
    "    SelectFromModel(estimator=ExtraTreesRegressor(max_features=0.9500000000000001, n_estimators=100), threshold=0.05),\n",
    "    RandomForestRegressor(bootstrap=True, max_features=0.45, min_samples_leaf=1, min_samples_split=5, n_estimators=100)\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "preds = exported_pipeline.predict(testing_features)\n",
    "\n",
    "np.savetxt(\"../predictions/preds.csv\", preds, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "#### In Regression, unlike Classification, accuracy is slightly harder to illustrate. It is impossible to predict the exact value but rather how close the prediction is against the real value.\n",
    "#### There are three main metrics for model evaluation in Regression:\n",
    " - R Square: measures how much of variability in dependent variable can be explained by the model. Determine how well the model fits the dependent variables.\n",
    " - Mean Square Error(MSE) and Root Mean Square Error (RMSE): MSE is an absolute measure of the goodness for the fit. Gives an absolute number on how much the predicted results deviate from the actual number. RMSE is the square root of MSE and is used more commonly than MSE because firstly sometimes MSE value can be too big to compare easily.\n",
    " - Mean Absolute Error(MAE): is similar to MSE but, instead of the sum of square of error, MAE is taking the sum of absolute value of error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Square (r2): 0.7937140332623703\n",
      "Root Mean Square Error (RMSE) 4.724684613902178\n",
      "Mean Absolute Error (MAE): 2.7985381280827126\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(testing_target, preds)\n",
    "\n",
    "rmse = mean_squared_error(testing_target, preds, squared=False)\n",
    "\n",
    "mae = mean_absolute_error(testing_target, preds)\n",
    "\n",
    "print(\"R Square (r2):\", r2)\n",
    "print(\"Root Mean Square Error (RMSE)\", rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
