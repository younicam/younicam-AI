{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "#### Model training using the TPOT exported pipeline and, then, model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tpot.builtins import StackingEstimator\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take the engineered data and perform split between train and test set. After some tentative we found that 20% for the test set and 80% for the training set was the best solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_data = pd.read_json(\"../data/engineered/presences.json\")\n",
    "features = tpot_data.drop('target', axis=1)\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'], test_size=0.20 ,random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After the splitting, we save the training and test features in order to perform some prediction evaluations if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_DATA_DIR = \"../data/segregation/\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(NEW_DATA_DIR)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "training_features.to_json(\"../data/segregation/presencesTrain.json\")\n",
    "testing_features.to_json(\"../data/segregation/presencesTest.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution of the TPOT exported pipeline with subsequent predictions saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_pipeline = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    RobustScaler(),\n",
    "    StackingEstimator(estimator=SGDRegressor(alpha=0.01, eta0=0.1, fit_intercept=False, l1_ratio=0.5, learning_rate=\"invscaling\", loss=\"squared_loss\", penalty=\"elasticnet\", power_t=0.1)),\n",
    "    SelectFromModel(estimator=ExtraTreesRegressor(max_features=0.9500000000000001, n_estimators=100), threshold=0.05),\n",
    "    RandomForestRegressor(bootstrap=True, max_features=0.45, min_samples_leaf=1, min_samples_split=5, n_estimators=100)\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "preds = exported_pipeline.predict(testing_features)\n",
    "\n",
    "np.savetxt(\"../predictions/preds.csv\", preds, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "#### In Regression, unlike Classification, accuracy is slightly harder to illustrate. It is impossible to predict the exact value but rather how close the prediction is against the real value.\n",
    "#### There are three main metrics for model evaluation in Regression:\n",
    " - R Square: measures how much of variability in dependent variable can be explained by the model. Determine how well the model fits the dependent variables.\n",
    " - Mean Square Error(MSE) and Root Mean Square Error (RMSE): MSE is an absolute measure of the goodness for the fit. Gives an absolute number on how much the predicted results deviate from the actual number. RMSE is the square root of MSE and is used more commonly than MSE because firstly sometimes MSE value can be too big to compare easily.\n",
    " - Mean Absolute Error(MAE): is similar to MSE but, instead of the sum of square of error, MAE is taking the sum of absolute value of error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Square (r2): 0.7881535934679571\n",
      "Root Mean Square Error (RMSE) 4.10359376773461\n",
      "Mean Absolute Error (MAE): 2.43473827818464\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(testing_target, preds)\n",
    "\n",
    "rmse = mean_squared_error(testing_target, preds, squared=False)\n",
    "\n",
    "mae = mean_absolute_error(testing_target, preds)\n",
    "\n",
    "print(\"R Square (r2):\", r2)\n",
    "print(\"Root Mean Square Error (RMSE)\", rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see, the results were not really good. They show that there are too much difference between the real values and the predicted ones probably because of the weak quantity of data.\n",
    "#### For this reason, we decided to oversample the data in order to see if the model performs better with a larger amount of data.  We used the Imbalanced-Learn library to perform a random oversample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "features_oversampled, target_oversampled = ros.fit_resample(features, tpot_data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As always, we store the intermediate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_DATA_DIR = \"../data/oversampled/\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(NEW_DATA_DIR)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "features_oversampled.to_json(\"../data/oversampled/features.json\")\n",
    "target_oversampled.to_json(\"../data/oversampled/target.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform again the splitting of data and store the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features_oversampled, target_oversampled, test_size=0.20 ,random_state=None)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "preds = exported_pipeline.predict(testing_features)\n",
    "\n",
    "np.savetxt(\"../predictions/preds_oversampled.csv\", preds, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the evaluation of model we can clearly see how much the model perfomance have increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Square (r2): 0.9989233839667933\n",
      "Root Mean Square Error (RMSE) 0.596933035434028\n",
      "Mean Absolute Error (MAE): 0.051922954284027135\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(testing_target, preds)\n",
    "\n",
    "rmse = mean_squared_error(testing_target, preds, squared=False)\n",
    "\n",
    "mae = mean_absolute_error(testing_target, preds)\n",
    "\n",
    "print(\"R Square (r2):\", r2)\n",
    "print(\"Root Mean Square Error (RMSE)\", rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
